{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\r\n",
    "!pip install findspark\r\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mrkolakowski\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/11.5 MB 12.2 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.9/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.5/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.0/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.6/11.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.7/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.2/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.8/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.3/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.9/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.4/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.0/11.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.5/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.6/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   ---------------------------------- ---- 450.6/505.5 kB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 505.5/505.5 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 345.4/345.4 kB 7.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "da4aa6a1"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import numpy as np\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from math import sqrt\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6bdfacb"
   },
   "source": [
    "# Funciones Aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9bprYH8jiDzA"
   },
   "outputs": [],
   "source": [
    "#funcion auxiliar\n",
    "def convertir_float(x):\n",
    "    array = []\n",
    "    for y in x:\n",
    "        try:\n",
    "            array.append(float(y))\n",
    "        except ValueError:\n",
    "            array.append(y)\n",
    "    if array:\n",
    "        array[-1] = int(array[-1])\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "238e05ce"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def get_y_hat(features, w):\n",
    "    # Assuming features is an array of features, w is a matrix of shape (1, 11)\n",
    "    return np.dot(features, w.T)  # Ensure w.T if w is (1, 11) and features is compatible\n",
    "\n",
    "def grad_cost(label, features, y_hat):\n",
    "    # Calculate gradient of cost function w.r.t. weights\n",
    "    return (y_hat - label) * features\n",
    "\n",
    "\n",
    "def get_derivatives(row, weights):\n",
    "    features = row[:-1]\n",
    "    y = row[-1]\n",
    "    y_hat = get_y_hat(features, weights)\n",
    "    dJ_dw = (y_hat - y) * np.append(features, 1)\n",
    "    return dJ_dw\n",
    "\n",
    "def update_ws(weights, dw, learning_rate):\n",
    "    return weights - learning_rate * dw\n",
    "\n",
    "\n",
    "def fcost(y, y_hat):\n",
    "    #print (\"cost:\",y,y_hat)\n",
    "    # compute loss/cost for one element \"y_hat\" and one label \"y\"\n",
    "    epsilon=0.00000001\n",
    "    if y == 1:\n",
    "        return -np.log(y_hat if y_hat > 0. else epsilon)\n",
    "    else:\n",
    "        return -np.log (1-y_hat if 1-y_hat >0. else epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cea3b70a"
   },
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bzkXSD_Dpu8f"
   },
   "outputs": [],
   "source": [
    "def RDD_df(rdd,schema):\n",
    "    \"\"\"\n",
    "    Muestra las primeras filas del DataFrame.\n",
    "\n",
    "    :param df: El DataFrame a visualizar\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir el RDD en DataFrame\n",
    "    df = spark.createDataFrame(rdd, schema=schema)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c4155acb"
   },
   "outputs": [],
   "source": [
    "def df_to_rdd(df):\n",
    "    \"\"\"\n",
    "    Convierte un DataFrame de PySpark en un RDD.\n",
    "\n",
    "    :param df: DataFrame de PySpark\n",
    "    :return: RDD de PySpark\n",
    "    \"\"\"\n",
    "    # Convertir el DataFrame a un RDD de filas\n",
    "    rdd = spark.sparkContext.parallelize(df_combinado.values.tolist())\n",
    "    rdd = rdd.map(lambda row: (list(row[:]), row[-1]))\n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "le20ppOs1van"
   },
   "outputs": [],
   "source": [
    "def normalize(rdd):\n",
    "    # Convert RDD to DataFrame with the correct structure\n",
    "    df = rdd.map(lambda x: Row(features=Vectors.dense(x[0]), label=x[1])).toDF([\"features\", \"label\"])\n",
    "\n",
    "    # Use MinMaxScaler for normalization\n",
    "    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "    scalerModel = scaler.fit(df)\n",
    "    scaledData = scalerModel.transform(df)\n",
    "\n",
    "    # Convert the DataFrame back to an RDD\n",
    "    normalized_rdd = scaledData.select(\"scaledFeatures\", \"label\").rdd.map(lambda row: (row.scaledFeatures.toArray().tolist(), row.label))\n",
    "\n",
    "    return normalized_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-bol0VrJLLHP"
   },
   "outputs": [],
   "source": [
    "def train(RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    # Initialize weight vector\n",
    "    w = np.random.randn(1, 11)\n",
    "\n",
    "    for i in range(iterations):\n",
    "                # Compute y_hat using map operation\n",
    "        rdd_y_hat = RDD_Xy.map(lambda x: (x[0], x[1], get_y_hat(x[0], w)))  # x[0] is features, x[1] is label\n",
    "\n",
    "        # Calculate cost and regularization\n",
    "        reg_term = lambda_reg * np.sum(w[:-1] ** 2)  # Regularization term\n",
    "\n",
    "        rdd_fcost = rdd_y_hat.map(lambda x: fcost(x[1], x[2]))  # Cost function value for each sample\n",
    "        J = rdd_fcost.reduce(lambda x, y: x + y)  # Sum up cost function across RDD\n",
    "        J += reg_term  # Add regularization term to total cost\n",
    "        J = J[0]\n",
    "\n",
    "        # Update weights\n",
    "        grad = rdd_y_hat.map(lambda x: grad_cost(x[1], x[0], x[2]))  # x[1] is label, x[0] is features, x[2] is y_hat\n",
    "        grad_sum = grad.reduce(lambda x, y: x + y)  # Sum up gradients across RDD\n",
    "\n",
    "        w = w - learning_rate * grad_sum - reg_term  # Update weight vector\n",
    "        print(f\"Iteration {i}  Cost:  {J}\")\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "20514222"
   },
   "outputs": [],
   "source": [
    "def predict(w,x):\n",
    "    threshold = 0.5\n",
    "    y_hat = get_y_hat(x,w)\n",
    "    return 1 if y_hat > threshold else 0\n",
    "\n",
    "def accuracy(RDD_Xy,w):\n",
    "    correct_answer= 0\n",
    "\n",
    "    def count_correct(Xy):\n",
    "        x,y = Xy\n",
    "        return 1 if predict(w,x) == y else 0\n",
    "    correct_answers = RDD_Xy.map(count_correct).reduce(lambda x,y: x+y)\n",
    "    return correct_answers*100/RDD_Xy.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8c8dc79"
   },
   "source": [
    "# Ejecucion lectura datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1cii2uh2UDJA"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de inicio\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 48275,
     "status": "ok",
     "timestamp": 1718998460336,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "8HMPfpdvsa44",
    "outputId": "9bedddd9-7cfe-4dc4-e725-c05b42720b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultimo URL leido:https://raw.githubusercontent.com/Meusz/FinOps/main/data/data_1.csv\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] Se produjo un error durante el intento de conexión ya que la parte conectada no respondió adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexión establecida ya que el host conectado no ha podido responder>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1344\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1344\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1345\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1336\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1382\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1381\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1382\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1470\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1470\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1001\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1000\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m-> 1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:853\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 853\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExceptionGroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_connection failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exceptions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:838\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    837\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 838\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] Se produjo un error durante el intento de conexión ya que la parte conectada no respondió adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexión establecida ya que el host conectado no ha podido responder",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m clear_output()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUltimo URL leido:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Convertir 'sport' y 'dport' a tipo numérico, ignorando los errores\u001b[39;00m\n\u001b[0;32m     37\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msport\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msport\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    533\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1392\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1347\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1344\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1345\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1348\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] Se produjo un error durante el intento de conexión ya que la parte conectada no respondió adecuadamente tras un periodo de tiempo, o bien se produjo un error en la conexión establecida ya que el host conectado no ha podido responder>"
     ]
    }
   ],
   "source": [
    "col_names = [\n",
    "    'pkSeqID', 'stime', 'flgs', 'proto', 'saddr', 'sport', 'daddr', 'dport',\n",
    "    'pkts', 'bytes', 'state', 'ltime', 'seq', 'dur', 'mean', 'stddev',\n",
    "    'smac', 'dmac', 'sum', 'min', 'max', 'soui', 'doui', 'sco', 'dco',\n",
    "    'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate',\n",
    "    'attack', 'category', 'subcategory'\n",
    "]\n",
    "\n",
    "# Definir los tipos de datos correspondientes a cada columna\n",
    "col_types = {\n",
    "    'pkSeqID': int, 'stime': float, 'flgs': str, 'proto': str,\n",
    "    'saddr': str, 'sport': float, 'daddr': str, 'dport': float, 'pkts': int, 'bytes': int,\n",
    "    'state': str,'ltime': float, 'seq': int, 'dur': float, 'mean': float, 'stddev': float, 'smac': str,\n",
    "    'dmac': str, 'sum': float, 'min': float, 'max': float, 'soui': float, 'doui': float,\n",
    "    'sco': float, 'dco': str, 'spkts': str, 'dpkts': str, 'sbytes': str, 'dbytes': str,\n",
    "    'rate': str, 'srate': str, 'drate': str, 'attack': str, 'category': str, 'subcategory': str\n",
    "}\n",
    "\n",
    "# Definir las URLs de los archivos CSV\n",
    "url_base = 'https://raw.githubusercontent.com/Meusz/FinOps/main/data/data_'\n",
    "urls = [url_base + str(i) + '.csv' for i in range(1, 19)]\n",
    "\n",
    "# Inicializar un DataFrame vacío\n",
    "df_combinado = pd.DataFrame(columns=col_names)\n",
    "# Convertir tipos de columnas según el diccionario col_types\n",
    "df_combinado = df_combinado.astype(col_types)\n",
    "\n",
    "\n",
    "# Descargar y combinar los archivos CSV en un DataFrame\n",
    "\n",
    "for url in urls:\n",
    "    clear_output()\n",
    "    print(f\"Ultimo URL leido:{url}\")\n",
    "\n",
    "    df = pd.read_csv(url,names=col_names,header=0)\n",
    "    # Convertir 'sport' y 'dport' a tipo numérico, ignorando los errores\n",
    "    df['sport'] = pd.to_numeric(df['sport'], errors='coerce')\n",
    "    df['dport'] = pd.to_numeric(df['dport'], errors='coerce')\n",
    "\n",
    "    # Llenar NaN en las columnas con un valor predeterminado, por ejemplo 0\n",
    "    df['pkts'].fillna(0, inplace=True)\n",
    "    df['bytes'].fillna(0, inplace=True)\n",
    "    df['seq'].fillna(0, inplace=True)\n",
    "\n",
    "    # Convertir las columnas a tipo int después de manejar NaN\n",
    "    df['pkts'] = df['pkts'].astype(int)\n",
    "    df['bytes'] = df['bytes'].astype(int)\n",
    "    df['seq'] = df['seq'].astype(int)\n",
    "\n",
    "    df=df.astype(col_types)\n",
    "    # Combinar los DataFrames\n",
    "    df_combinado = pd.concat([df_combinado, df])\n",
    "    del df\n",
    "\n",
    "\n",
    "# Mostrar el DataFrame combinado\n",
    "clear_output()\n",
    "\n",
    "df_combinado.drop(df_combinado[df_combinado['category'] == 'nan'].index, inplace=True)\n",
    "\n",
    "#[\"flgs\", \"proto\", \"pkts\", \"bytes\", \"dur\", \"mean\", \"stddev\", \"sum\", \"min\", \"max\", \"rate\", \"category\"]\n",
    "\n",
    "df_combinado.loc[df_combinado[\"proto\"] == \"tcp\", \"proto\"] = 0\n",
    "df_combinado.loc[df_combinado[\"proto\"] == \"udp\", \"proto\"] = 1\n",
    "df_combinado.loc[df_combinado[\"proto\"] == \"icmp\", \"proto\"] = 2\n",
    "df_combinado.loc[df_combinado[\"proto\"] == \"arp\", \"proto\"] = 3\n",
    "df_combinado.loc[df_combinado[\"proto\"] == \"ipv6-icmp\", \"proto\"] = 4\n",
    "df_combinado.loc[df_combinado[\"proto\"] == \"igmp\", \"proto\"] = 4\n",
    "df_combinado.loc[df_combinado[\"proto\"] == \"rarp\", \"proto\"] = 4\n",
    "\n",
    "\n",
    "\n",
    "df_combinado.loc[df_combinado[\"category\"] == \"Reconnaissance\", \"category\"] = 0\n",
    "df_combinado.loc[df_combinado[\"category\"] == \"DoS\", \"category\"] = 1\n",
    "df_combinado.loc[df_combinado[\"category\"] == \"Normal\", \"category\"] = 2\n",
    "df_combinado.loc[df_combinado[\"category\"] == \"Theft\", \"category\"] = 3\n",
    "df_combinado.loc[df_combinado[\"category\"] == \"Reconnai\", \"category\"] = 4\n",
    "\n",
    "df_combinado['category'] = df_combinado['category'].astype(int)\n",
    "df_combinado['proto'] = df_combinado['proto'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_combinado = df_combinado.dropna(subset=[\"flgs\", \"proto\", \"pkts\", \"bytes\", \"dur\", \"mean\", \"stddev\", \"sum\", \"min\", \"max\", \"rate\", \"category\"])\n",
    "#df_combinado.drop(df_combinado[df_combinado['daddr'] == 'nan'].index, inplace=True)\n",
    "df_combinado['proto'] = df_combinado['proto'].astype(int)\n",
    "df_combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13701,
     "status": "ok",
     "timestamp": 1718998474035,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "XRoLPsPVyAHz",
    "outputId": "1620dabf-b563-4b13-d641-3350751cebd2"
   },
   "outputs": [],
   "source": [
    "# Se eliminan las columnas innecesarias del DataFrame\n",
    "df_combinado=df_combinado.drop(columns = ['pkSeqID', 'stime', 'flgs', 'ltime', 'seq', 'smac',  'dmac', 'soui', 'doui', 'sco', 'dco', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'srate', 'drate', 'attack', 'subcategory'])\n",
    "\n",
    "# Selecciona las columnas de tipo 'object' en el DataFrame  y devuelve sus nombres\n",
    "print(df_combinado.select_dtypes(include=['object']).columns)\n",
    "\n",
    "# Calcula la cantidad de valores NaN por columna en el DataFrame\n",
    "print(df_combinado.isna().sum())\n",
    "\n",
    "\n",
    "# Elimina las filas donde la columna 'sport' tiene valores NaN en el DataFrame\n",
    "\n",
    "df_combinado = df_combinado.dropna(subset=['sport','proto'])\n",
    "\n",
    "# Elimina las filas duplicadas\n",
    "df_combinado.drop_duplicates(inplace = True)\n",
    "\n",
    "# Elimina las columnas especificadas del DataFrame\n",
    "df_combinado = df_combinado.drop(columns = ['saddr', 'daddr',  'state', 'sport', 'dport'])\n",
    "\n",
    "\n",
    "print(df_combinado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Rowsz4l-b20"
   },
   "outputs": [],
   "source": [
    "# Extraer el archivo CSV del ZIP y cargarlo en un DataFrame\n",
    "nIter = 5\n",
    "learningRate = 0.1\n",
    "lambda_reg = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1718998474035,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "g3iqdmBSrHoI",
    "outputId": "c0745952-7309-4541-d242-fa760fc58ab0"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de finalización\n",
    "end_time = time.time()\n",
    "# Calcular y mostrar el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "print(f'Tiempo de ejecución: {execution_time:.2f} segundos, {execution_time/60:.2f}  minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7YN-Sltq_-x"
   },
   "source": [
    "# Ejecucion entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xt5PCCh1rKXz"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de inicio\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5175,
     "status": "ok",
     "timestamp": 1718998479199,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "uMg2JaA1jnwU",
    "outputId": "8db879ee-0331-4733-acc6-7fc258f68ce3"
   },
   "outputs": [],
   "source": [
    "# Convertir el DataFrame de Spark a un RDD\n",
    "data = df_to_rdd(df_combinado)\n",
    "print(data.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63921,
     "status": "ok",
     "timestamp": 1718998543110,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "dW52k7E8z7ng",
    "outputId": "79e3b908-cbfa-4586-ad51-e018dd12fc55"
   },
   "outputs": [],
   "source": [
    "# Normalize the numeric RDD\n",
    "data_normalized =normalize(data)\n",
    "print(data_normalized.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1069715,
     "status": "ok",
     "timestamp": 1718999612816,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "DTWUjQhhCBY3",
    "outputId": "4ecf2c27-6d1e-4297-95c4-288c8624fbc8"
   },
   "outputs": [],
   "source": [
    "# Entrenar el modelo con RDDs\n",
    "ws = train(data_normalized, nIter, learningRate, lambda_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183188,
     "status": "ok",
     "timestamp": 1718999795992,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "2NwGC4e8uhEh",
    "outputId": "083812e9-6a1b-4a46-e8bb-916c4144a3a5"
   },
   "outputs": [],
   "source": [
    "# Calcular la precisión\n",
    "acc = accuracy(data_normalized, ws)\n",
    "\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1718999795992,
     "user": {
      "displayName": "Mateusz Roman Kolakowski Dziewic (Meusz)",
      "userId": "11955788477668933942"
     },
     "user_tz": -120
    },
    "id": "H8veToYpT_N4",
    "outputId": "459ad536-3e71-4385-9cdb-ebf2b7a4c2d0"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de finalización\n",
    "end_time = time.time()\n",
    "# Calcular y mostrar el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "print(f'Tiempo de ejecución: {execution_time:.2f} segundos, {execution_time/60:.2f}  minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e684e20e"
   },
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dfe54ff"
   },
   "source": [
    "## Funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99e46a59"
   },
   "outputs": [],
   "source": [
    "def transforma(RDD_Xy):\n",
    "    import random\n",
    "    #RDD_Xy_con_indice = RDD_Xy.zipWithIndex()\n",
    "    #RDD_Xy_con_clave = RDD_Xy_con_indice.map(lambda x: (x[0],(x[1]%num_block_cv)))\n",
    "    \"\"\"Si zipWithIndex no esta permitido, quiza podemos utilizar randint(0, num_bloques-1) para\n",
    "    generar claves, aun que la proporcion de tamaño de tran y test en este caso no es determinado\"\"\"\n",
    "    RDD_Xy_con_indice = RDD_Xy.map(lambda x: (x,random.randint(0, num_block_cv-1)))\n",
    "    RDD_Xy_con_clave = RDD_Xy_con_indice.map(lambda x: (x[0],(x[1]%num_block_cv)))\n",
    "\n",
    "    return RDD_Xy_con_clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ddb5b68"
   },
   "outputs": [],
   "source": [
    "def get_block_data(RDD_Xy, clave):\n",
    "    train = RDD_Xy.flatMap(lambda x: [x] if x[1] != clave else []).map(lambda x: x[0])\n",
    "    test = RDD_Xy.flatMap(lambda x: [x] if x[1] == clave else []).map(lambda x: x[0])\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e7460e9"
   },
   "source": [
    "## Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0S13Xs3UKfO"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de inicio\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7312ad97"
   },
   "outputs": [],
   "source": [
    "#definir cuantas bloques quiere dividir para cross-validation\n",
    "num_block_cv = 5\n",
    "avg_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c660ddc5"
   },
   "outputs": [],
   "source": [
    "#Ya tenemos data_normalized\n",
    "data_cv = transforma(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "522caa75",
    "outputId": "8ee16c88-3ce1-4de8-bf55-acacbf177ddd"
   },
   "outputs": [],
   "source": [
    "for i in range(num_block_cv):\n",
    "    print(f\"Cross-Validation con clave:{i}\")\n",
    "    train_data,test = get_block_data(data_cv,i)\n",
    "    ws = train(train_data,nIter,learningRate,lambda_reg)\n",
    "    acc = accuracy(data_normalized,ws)\n",
    "    avg_acc += avg_acc\n",
    "    print(\"acc:\" , acc)\n",
    "print(\"averge acc:\" , avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPUuXFeEUNAx"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de finalización\n",
    "end_time = time.time()\n",
    "# Calcular y mostrar el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "print(f'Tiempo de ejecución: {execution_time:.2f} segundos, {execution_time/60:.2f}  minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50cf732c"
   },
   "source": [
    "# Graficos para el informe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b727018"
   },
   "source": [
    "## funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0053049d"
   },
   "outputs": [],
   "source": [
    "def train_visualizacion(RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    # Initialize weight vector\n",
    "    m = RDD_Xy.count()  # Number of samples in RDD\n",
    "    num_columns = len(RDD_Xy.take(1)[0][0])  # Number of columns in features + 1 (for bias)\n",
    "    w = np.random.randn(1, 11)\n",
    "    costos_entrenamiento = []  # List to store training costs (objective function + regularization)\n",
    "    tiempos = []              # List to store training times\n",
    "    for i in range(iterations):\n",
    "        start_time = time.time()  # Start time of iteration\n",
    "        # Compute y_hat using map operation\n",
    "        rdd_y_hat = RDD_Xy.map(lambda x: (x[0], x[1], get_y_hat(x[0], w)))  # x[0] is features, x[1] is label\n",
    "\n",
    "        # Calculate cost and regularization\n",
    "        reg_term = lambda_reg * np.sum(w[:-1] ** 2)  # Regularization term\n",
    "\n",
    "        rdd_fcost = rdd_y_hat.map(lambda x: fcost(x[1], x[2]))  # Cost function value for each sample\n",
    "        J = rdd_fcost.reduce(lambda x, y: x + y)  # Sum up cost function across RDD\n",
    "        J += reg_term  # Add regularization term to total cost\n",
    "        J = J[0]\n",
    "        # Append current iteration's cost to list\n",
    "        costos_entrenamiento.append(J)\n",
    "\n",
    "        # Update weights\n",
    "        grad = rdd_y_hat.map(lambda x: grad_cost(x[1], x[0], x[2]))  # x[1] is label, x[0] is features, x[2] is y_hat\n",
    "        grad_sum = grad.reduce(lambda x, y: x + y)  # Sum up gradients across RDD\n",
    "\n",
    "        w = w - learning_rate * grad_sum - reg_term  # Update weight vector\n",
    "        print(f\"Iteration {i}  Cost:  {J}\")\n",
    "\n",
    "\n",
    "        end_time = time.time()  # End time of iteration\n",
    "        tiempo = end_time - start_time  # Duration of iteration\n",
    "        tiempos.append(tiempo)  # Append duration to list\n",
    "    return w, tiempos, costos_entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86b55f26"
   },
   "source": [
    "## Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6HRiSirUQw0"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de inicio\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3222c4e0"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "ws,tiempos, costos_entrenamiento = train_visualizacion(data_normalized,nIter, learningRate,lambda_reg)\n",
    "acc = accuracy(data_normalized,ws)\n",
    "\n",
    "print(\"acc:\" , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9b52700"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(costos_entrenamiento, label='Costo por Iteración')\n",
    "plt.xlabel('Iteración')\n",
    "plt.ylabel('Costo de Entrenamiento')\n",
    "plt.title('Costo de Entrenamiento por Iteración')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(tiempos, label='Tiempo por Iteración')\n",
    "plt.xlabel('Iteración')\n",
    "plt.ylabel('Tiempo (s)')\n",
    "plt.title('Tiempo de Ejecución por Iteración')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcf99f73"
   },
   "outputs": [],
   "source": [
    "\n",
    "avg_acc = 0\n",
    "precisiones = []\n",
    "num_registros_train = []\n",
    "num_registros_test = []\n",
    "\n",
    "for i in range(num_block_cv):\n",
    "    print(f\"Cross-Validation con clave:{i}\")\n",
    "    train_data, test = get_block_data(data_cv, i)\n",
    "    num_registros_train.append(train_data.count())\n",
    "    num_registros_test.append(test.count())\n",
    "    ws = train(train_data, nIter, learningRate, lambda_reg)\n",
    "    acc = accuracy(test, ws)\n",
    "    precisiones.append(acc)\n",
    "    avg_acc += acc\n",
    "    print(\"Número de registros en train:\", num_registros_train[-1])\n",
    "    print(\"Número de registros en test:\", num_registros_test[-1])\n",
    "    print(\"acc:\", acc)\n",
    "\n",
    "avg_acc /= num_block_cv\n",
    "print(\"Average accuracy:\", avg_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "920aa10e"
   },
   "outputs": [],
   "source": [
    "num_registros_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca947038"
   },
   "outputs": [],
   "source": [
    "num_registros_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e40a71c8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Bloque de CV')\n",
    "ax1.set_ylabel('Precisión', color=color)\n",
    "ax1.plot(precisiones, label='Precisión por bloque de CV', color=color, marker='o')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_xticks(np.arange(num_block_cv))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Número de registros', color=color)\n",
    "ax2.plot(num_registros_train, label='Registros en Train', color='blue', marker='x', linestyle='--')\n",
    "ax2.plot(num_registros_test, label='Registros en Test', color='cyan', marker='x', linestyle='--')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes)\n",
    "plt.title('Precisión y Número de Registros por Bloque de CV')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c0c4f61"
   },
   "outputs": [],
   "source": [
    "num_workers_list = [1, 2, 3, 4,5,6,7,8,9]\n",
    "tiempos_por_worker = []\n",
    "speedup_por_worker = []\n",
    "\n",
    "for num_workers in num_workers_list:\n",
    "    costos_entrenamiento = []\n",
    "    sc.stop()\n",
    "    sc = SparkContext(f\"local[{num_workers}]\", f\"Test_{num_workers}_workers\")\n",
    "\n",
    "    init_time = time.time()\n",
    "    #data = readFile(path)\n",
    "    #data = normalize(data)\n",
    "    #ws,tiempos, costos_entrenamiento = train_visualizacion(data_normalized,nIter, learningRate,lambda_reg)\n",
    "    #acc = accuracy(data_normalized, ws)\n",
    "    fin_time = time.time()\n",
    "    plt.xlabel(\"Iteración\")\n",
    "    plt.ylabel(\"Costo\")\n",
    "    plt.title(f\"Costo de entrenamiento con {num_workers}\")\n",
    "    plt.legend(num_workers_list, loc=\"best\")\n",
    "    plt.plot(costos_entrenamiento, color=f\"C{num_workers}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    tiempo_total = fin_time - init_time\n",
    "    tiempos_por_worker.append(tiempo_total)\n",
    "\n",
    "    print(f\"Workers: {num_workers}, Acc: {acc}, Tiempo: {tiempo_total}\")\n",
    "\n",
    "    sc.stop()\n",
    "\n",
    "tiempo_con_1_worker = tiempos_por_worker[0]\n",
    "speedup_por_worker = [tiempo_con_1_worker / tiempo for tiempo in tiempos_por_worker]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(num_workers_list, tiempos_por_worker, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Número de Workers')\n",
    "plt.ylabel('Tiempo de ejecución (s)')\n",
    "plt.title('Curva de Rendimiento')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(num_workers_list, speedup_por_worker, marker='o', linestyle='-', color='r')\n",
    "plt.xlabel('Número de Workers')\n",
    "plt.ylabel('Speedup')\n",
    "plt.title('Curva de Speedup')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBQ9Iye9UUnl"
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de finalización\n",
    "end_time = time.time()\n",
    "# Calcular y mostrar el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "print(f'Tiempo de ejecución: {execution_time:.2f} segundos, {execution_time/60:.2f}  minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e00EcwB1Opn0"
   },
   "source": [
    "# Analizar componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dU4pH0iwOxYs"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import subprocess\n",
    "\n",
    "# Obtener información del procesador\n",
    "cpu_info = os.popen(\"cat /proc/cpuinfo | grep 'model name' | uniq\").read().strip()\n",
    "print(f'Modelo de procesador: {cpu_info}')\n",
    "\n",
    "# Número de procesadores físicos\n",
    "num_processors = psutil.cpu_count(logical=False)\n",
    "print(f'Número de procesadores físicos: {num_processors}')\n",
    "\n",
    "# Número de vCores\n",
    "num_vcores = psutil.cpu_count(logical=True)\n",
    "print(f'Número de vCores (procesadores lógicos): {num_vcores}')\n",
    "\n",
    "# Capacidad de memoria\n",
    "mem = psutil.virtual_memory()\n",
    "total_memory_gb = mem.total / (1024 ** 3)  # Convertir bytes a GB\n",
    "available_memory_gb = mem.available / (1024 ** 3)  # Convertir bytes a GB\n",
    "print(f'Capacidad total de memoria RAM: {total_memory_gb:.2f} GB')\n",
    "print(f'Memoria RAM disponible: {available_memory_gb:.2f} GB')\n",
    "\n",
    "# Información del disco duro\n",
    "disk_usage = psutil.disk_usage('/')\n",
    "total_disk_gb = disk_usage.total / (1024 ** 3)  # Convertir bytes a GB\n",
    "used_disk_gb = disk_usage.used / (1024 ** 3)    # Convertir bytes a GB\n",
    "free_disk_gb = disk_usage.free / (1024 ** 3)    # Convertir bytes a GB\n",
    "print(f'Capacidad total del disco duro: {total_disk_gb:.2f} GB')\n",
    "print(f'Espacio utilizado del disco duro: {used_disk_gb:.2f} GB')\n",
    "print(f'Espacio libre del disco duro: {free_disk_gb:.2f} GB')\n",
    "\n",
    "# Tipo de disco duro\n",
    "disk_info = os.popen(\"lsblk -o NAME,ROTA,TYPE,SIZE | grep '^sda'\").read().strip()\n",
    "print(f'Tipo de disco duro: {disk_info}')\n",
    "\n",
    "# Información del nodo\n",
    "node_info = os.uname()\n",
    "print(f'Información del nodo: {node_info}')\n",
    "\n",
    "# Información detallada del sistema\n",
    "print(f'Información detallada del sistema:')\n",
    "print(f'Sistema: {node_info.sysname}')\n",
    "print(f'Nombre del nodo: {node_info.nodename}')\n",
    "print(f'Release: {node_info.release}')\n",
    "print(f'Versión: {node_info.version}')\n",
    "print(f'Máquina: {node_info.machine}')\n",
    "\n",
    "# Obtener información de la GPU\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(\"nvidia-smi --query-gpu=name --format=csv,noheader\", shell=True).decode('utf-8').strip()\n",
    "    print(f'Modelo de GPU: {gpu_info}')\n",
    "except subprocess.CalledProcessError:\n",
    "    print('No se detectó GPU o NVIDIA-SMI no está instalado.')\n"
   ]
  }
 ],
 "metadata": {
  "description": null,
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
